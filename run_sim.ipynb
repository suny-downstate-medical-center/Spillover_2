{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "378f076f-487c-4cb4-96a4-a63231d2324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:556: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:556: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_168842/589707722.py:556: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  s_ind = [int(si) for si in re.findall(\"\\d+\", sec.name())]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Aug  2 17:50:36 2019\n",
    "\n",
    "@author: daniel\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec 15 17:48:41 2016\n",
    "\n",
    "@author: sid\n",
    "\"\"\"\n",
    "import os,sys,traceback\n",
    "from neuron import h\n",
    "import d1msn as d1msn\n",
    "import d2msn as d2msn\n",
    "import spillover_experiment as pe\n",
    "import pickle\n",
    "import parameters as p\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import scipy.signal as ss\n",
    "import pandas as pd\n",
    "import spine as sp\n",
    "from math import exp\n",
    "\n",
    "class nmda_sim:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        dMSN_library = 'D1_71bestFit_updRheob.pkl'\n",
    "        iMSN_library = 'D2_34bestFit_updRheob.pkl' \n",
    "\n",
    "        self.data_list = []\n",
    "        self.neuron_id_list = []\n",
    "\n",
    "        self.neuron_id = ''\n",
    "        self.neuron_name = ''\n",
    "        self.archive = ''\n",
    "        self.note = ''\n",
    "        self.sec_num = 0\n",
    "        self.variables = ''\n",
    "        self.params = ''\n",
    "\n",
    "        self.error = False\n",
    "        # self.insert_channels(variables)\n",
    "        self.esyn = []\n",
    "        self.isyn = []\n",
    "        self.spines = []\n",
    "        # self.num_spines_on_dends = np.zeros(len(self.dendlist))\n",
    "        \n",
    "        found = False\n",
    "        print ( \" ********* \")\n",
    "        # for dir_name in os.listdir('morphology/msn_morphologies'):\n",
    "        #     data = dir_name.split(\"_\")\n",
    "            \n",
    "        #     folder_number = int(data[1])\n",
    "        files=[]\n",
    "        \n",
    "        d1_files = []\n",
    "        d2_files = []\n",
    "        \n",
    "        d1_files_good = []\n",
    "        d2_files_good = []\n",
    "        \n",
    "        d1_files_bad = []\n",
    "        d2_files_bad = []\n",
    "        \n",
    "        df = pd.read_csv('soma.tsv',index_col=None, sep=\"\\t\")\n",
    "        # print(df.columns)\n",
    "        # print(df.head())\n",
    "        cell_ID =22\n",
    "        with open(dMSN_library, 'rb') as f:\n",
    "            d1_model_sets  = pickle.load(f, encoding=\"latin1\")\n",
    "            self.variables = d1_model_sets[cell_ID]['variables']        \n",
    "        \n",
    "        with open(iMSN_library, 'rb') as f:\n",
    "            d2_model_sets  = pickle.load(f, encoding=\"latin1\")\n",
    "            self.variables = d2_model_sets[cell_ID]['variables']        \n",
    "        \n",
    "        for index,row in df.iterrows():\n",
    "\n",
    "            # print (row['domain'])\n",
    "\n",
    "            self.neuron_id = row['neuron_id']\n",
    "            self.neuron_name = row['neuron_name']\n",
    "            print (self.neuron_name)\n",
    "            self.archive = row['archive']\n",
    "            self.note = row['note']\n",
    "            self.length = row['length']\n",
    "            cell_type_val = row['cell_type_val']\n",
    "\n",
    "            if self.length < 4000: \n",
    "                continue\n",
    "                \n",
    "            archive = row['archive']\n",
    "            neuron_name = row['neuron_name']\n",
    "            \n",
    "            if cell_type_val and isinstance(cell_type_val, str):\n",
    "                file_name = '../all_morphologies/' + archive.lower() + '/CNG version/' + neuron_name + '.CNG.swc'\n",
    "                print ('../all_morphologies/' + archive.lower() + '/CNG version/' + neuron_name + '.CNG.swc')\n",
    "                # file_name = 'morphology/WT-dMSN_P270-20_1.02_SGA1-m24.swc'\n",
    "                # cell_type_val = 'D1'\n",
    "                if cell_type_val == 'D1':\n",
    "\n",
    "                    print (\" $$ D1 $$ \")\n",
    "                    \n",
    "                    d1_files.append(file_name)  \n",
    "                    self.params = \"./params_dMSN.json\"\n",
    "        \n",
    "                    try:\n",
    "                        Import = h.Import3d_SWC_read()\n",
    "                        Import.input(file_name)\n",
    "                        imprt = h.Import3d_GUI(Import, 0)\n",
    "                        imprt.instantiate(None)\n",
    "                        h.define_shape()         \n",
    "\n",
    "                        self.create_sectionlists()\n",
    "                        self.set_nsegs()\n",
    "                        \n",
    "                        d1_files_good.append(file_name)  \n",
    "                        h.celsius = 35\n",
    "                        self.v_init = -80\n",
    "\n",
    "                        # dmax, sec = self.max_dist()\n",
    "                        # print('dmax 1111 ', dmax, ' sec ' , sec)\n",
    "                        \n",
    "                        # sec_name = sec.name()\n",
    "                        # sec_index = sec_name.find(\"[\")\n",
    "                        # sec_num = int(sec_name[sec_index+1:sec_name.find(\"]\")])\n",
    "                        # print ( \" sec num \", sec_num )   \n",
    "                        # self.sec_num = sec_num\n",
    "\n",
    "                        # self.run_cell_sim()                    \n",
    "                        \n",
    "                    except:\n",
    "                        traceback.print_exc(file=sys.stdout)\n",
    "                        print (\" error loading file \" , file_name)\n",
    "                        d1_files_bad.append(file_name)  \n",
    "                        \n",
    "                elif cell_type_val == 'D2':\n",
    "\n",
    "                    print (\" $$ D2 $$ \")\n",
    "                    \n",
    "                    d2_files.append(file_name)  \n",
    "                    self.params = \"./params_iMSN.json\"\n",
    "        \n",
    "                    try:\n",
    "                        Import = h.Import3d_SWC_read()\n",
    "                        Import.input(file_name)\n",
    "                        imprt = h.Import3d_GUI(Import, 0)\n",
    "                        imprt.instantiate(None)\n",
    "                        h.define_shape()         \n",
    "                        self.create_sectionlists()\n",
    "                        self.set_nsegs()\n",
    "                        h.celsius = 35\n",
    "                        self.v_init = -80\n",
    "                        # dmax, sec = self.max_dist()\n",
    "                        # print('dmax 2222 ', dmax, ' sec ' , sec)\n",
    "\n",
    "                        d2_files_good.append(file_name)  \n",
    "                        \n",
    "                        # sec_name = sec.name()\n",
    "                        # sec_index = sec_name.find(\"[\")\n",
    "                        # sec_num = int(sec_name[sec_index+1:sec_name.find(\"]\")])\n",
    "                        # print ( \" sec num \", sec_num ) \n",
    "                        # self.sec_num = sec_num\n",
    "    \n",
    "                        # self.run_cell_sim()\n",
    "        \n",
    "                    except:\n",
    "                        traceback.print_exc(file=sys.stdout)\n",
    "                        print (\" error loading file \" , file_name)\n",
    "                        d2_files_bad.append(file_name)                  \n",
    "            # break\n",
    "        \n",
    "        df_good = pd.DataFrame(data = self.data_list, columns = ['neuron_id','neuron_name','archive','note'], index = None)\n",
    "        \n",
    "        df_good.to_csv(\"good_files.tsv\", sep=\"\\t\", index=None)\n",
    "\n",
    "        df_soma = df[df['neuron_id'].isin(self.neuron_id_list)]\n",
    "        # df_soma.to_csv(\"soma.tsv\",sep=\"\\t\",index=None)\n",
    "        \n",
    "        print (\" all d1 = \" , len(d1_files))\n",
    "        print (\" d1 good \" , len(d1_files_good))\n",
    "        print (\" d1 bad \" , len(d1_files_bad))\n",
    "        \n",
    "        print (\" all d2 \", len(d2_files))\n",
    "        print (\" d2 good \", len(d2_files_good))\n",
    "        print (\" d2 bad \" , len(d2_files_bad))\n",
    "\n",
    "    def run_cell_sim(self):\n",
    "        try:\n",
    "\n",
    "            self.insert_channels(self)\n",
    "            \n",
    "            dend_record_list = [self.sec_num] #[3,4,9,10,21,22,24,26,35,36,51,52]\n",
    "            dend_stim_list = []#[3,4,9,10,35,36]                    \n",
    "            plateau_cluster_list = [self.sec_num]        \n",
    "    \n",
    "            plateau_cluster_size = np.arange(1,5,1)\n",
    "    \n",
    "            vs = []\n",
    "            vspine = []\n",
    "            vd = []\n",
    "            legend = []\n",
    "    \n",
    "            max_vs = []\n",
    "            max_vspine = []\n",
    "            max_vd = []\n",
    "            g_nmda = []\n",
    "            i_nmda = []\n",
    "    \n",
    "            sns.set(font_scale = 1.0)\n",
    "            sns.set_style('whitegrid')\n",
    "            # fig_vs = plt.figure(); \n",
    "            # fig_vspine = plt.figure(); \n",
    "            # fig_vd = plt.figure();\n",
    "            \n",
    "            # ax_vs = fig_vs.add_subplot(111); ax_vs.set_ylabel('Vs (mV)'); ax_vs.set_xlabel('t (ms)')\n",
    "            # ax_vspine = fig_vspine.add_subplot(111); ax_vspine.set_ylabel('Vspine (mV)'); ax_vspine.set_xlabel('t (ms)')\n",
    "            # ax_vd = fig_vd.add_subplot(111); ax_vd.set_ylabel('Vd (mV)'); ax_vd.set_xlabel('t (ms)')\n",
    "            # colors = sns.color_palette(\"coolwarm\", plateau_cluster_size.max())\n",
    "    \n",
    "            add_spine = 0\n",
    "            on_spine = 1\n",
    "    \n",
    "            self.insert_spines(plateau_cluster_list, p.cluster_start_pos, p.cluster_end_pos, num_spines = p.plateau_cluster_size_max)             \n",
    "    \n",
    "            # sns.set_style(\"ticks\")\n",
    "            # for num_syns in plateau_cluster_size:\n",
    "    \n",
    "            #     ex = pe.Spillover_Experiment('record_ca', cell)\n",
    "            #     ex.insert_synapses('noise_SPN')\n",
    "            #     ex.insert_synapses('my_spillover', plateau_cluster_list, deterministic = 0, \n",
    "            #                     num_syns = num_syns, add_spine = add_spine, on_spine = on_spine)\n",
    "    \n",
    "            #     ex.set_up_recording(dend_record_list)\n",
    "            #     ex.simulate()\n",
    "            #     tv = ex.tv.to_python()\n",
    "            #     t = ex.t.to_python()\n",
    "            #     legend.append(\"%d syns\" % num_syns)\n",
    "    \n",
    "            #     if add_spine == 1 or on_spine == 1:\n",
    "            #         vspine.append(ex.vspine[0].to_python())\n",
    "            #         max_vspine.append(max(ex.vspine[0]))\n",
    "            #         ax_vspine.plot(tv, ex.vspine[0].to_python(), color = colors[num_syns-1])\n",
    "    \n",
    "            #     vd.append(ex.vdlist[0].to_python())\n",
    "            #     max_vd.append(max(ex.vdlist[0])) \n",
    "                \n",
    "            #     max_vs.append(max(ex.vs))\n",
    "            #     vs.append(ex.vs.to_python())\n",
    "                    \n",
    "            #     cell.esyn = []\n",
    "            #     ex.estim = []\n",
    "            #     ex.enc = []\n",
    "            #     for s in cell.spines:\n",
    "            #         s.syn_on = 0\n",
    "            #     cell.isyn = []\n",
    "            #     ex.istim = []\n",
    "            #     ex.inc = []\n",
    "            # #\n",
    "            # vs_indices = []; vs_widths = []\n",
    "            # vd_indices = []; vd_widths = []\n",
    "            # vspine_indices = []; vspine_wid = []\n",
    "            # for v in vs:\n",
    "            #     vs_indices.append(ss.find_peaks(v))\n",
    "            #     vs_widths.append(ss.peak_widths(v, (vs_indices[-1])[0], rel_height = 0.15))\n",
    "    \n",
    "            # for v in vd:\n",
    "            #     vd_indices.append(ss.find_peaks(v))\n",
    "            #     vd_widths.append(ss.peak_widths(v, (vd_indices[-1])[0] ,rel_height = 0.15))\n",
    "                \n",
    "            # for i in range(0, len(vs)):    \n",
    "            #     if add_spine ==0 and on_spine ==0:    \n",
    "            #         ax_vd.plot(tv, vd[i]);   \n",
    "            #     ax_vs.plot(tv, vs[i], color = colors[i]); ax_vs.set_title(\"weight = %.2f, Cdur_factor = %d\" % (p.weight, p.eCdur_factor))\n",
    "            #     ax_vd.plot(tv, vd[i], color = colors[i]); ax_vs.set_title(\"weight = %.2f, Cdur_factor = %d\" % (p.weight, p.eCdur_factor))\n",
    "            # ax_vd.set_title(\"weight = %.2f, Cdur_factor = %d\" % (p.weight, p.eCdur_factor))\n",
    "                \n",
    "            # sns.despine()\n",
    "            # res_dict = {'t': t,\n",
    "            #             'vs': vs,\n",
    "            #             'vspine': vspine}\n",
    "            # to_save = json.dumps(res_dict)\n",
    "            # #filename = './results/data_spillover_steep.dat'\n",
    "            # #with open(filename,'w', encoding = 'utf-8') as f:\n",
    "            # #    json.dump(to_save, f)\n",
    "            # plt.savefig(\"plots/\" + cell_type + \"_\" + str(folder_number)+\"_\" + morphology.replace(\".\",\"_\") + \".png\")\n",
    "    \n",
    "        except:\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "                   \n",
    "    def insert_channels(self, variables = None):\n",
    "        self.dendritic_channels =   [\n",
    "                    \"naf\",      \n",
    "                    \"kaf\",\n",
    "                    \"kas\",\n",
    "                    \"kdr\",\n",
    "                    \"kir\",\n",
    "                    \"cal12\",\n",
    "                    \"cal13\",\n",
    "                    \"can\",\n",
    "                    \"car\",\n",
    "                    \"cav32\",\n",
    "                    \"cav33\",\n",
    "                    \"sk\",\n",
    "                    \"bk\"            ]\n",
    "                \n",
    "        self.somatic_channels = [\n",
    "                    \"naf\",\n",
    "                    \"kaf\",\n",
    "                    \"kas\",\n",
    "                    \"kdr\",\n",
    "                    \"kir\",\n",
    "                    \"cal12\",\n",
    "                    \"cal13\",\n",
    "                    \"can\",\n",
    "                    \"car\",\n",
    "                    \"sk\",\n",
    "                    \"bk\"        ]\n",
    "                    \n",
    "        self.axonal_channels = [\n",
    "                    \"naf\",\n",
    "                    \"kas\",\n",
    "                    \"Im\"        ]        \n",
    "\n",
    "        # Load ion channel parameters\n",
    "        with open(self.params) as file:\n",
    "            par = json.load(file)\n",
    "        \n",
    "        for sec in self.somalist:\n",
    "            for mech in self.somatic_channels+[\"cadyn\", \"caldyn\"]:\n",
    "                sec.insert(mech)\n",
    "                \n",
    "        for sec in self.axonlist:\n",
    "            for mech in self.axonal_channels:\n",
    "                sec.insert(mech)\n",
    "                \n",
    "        for sec in self.dendlist:\n",
    "            for mech in self.dendritic_channels+[\"cadyn\", \"caldyn\", \"cadyn_nmda\"]:\n",
    "                sec.insert(mech)\n",
    "            sec.taur_cadyn_nmda = p.tau_cadyn_nmda\n",
    "\n",
    "        for sec in self.all:\n",
    "            sec.Ra = 150\n",
    "            sec.cm = 1.0\n",
    "            sec.insert('pas')\n",
    "            sec.g_pas = float(par['g_pas_all']['Value'])\n",
    "            sec.e_pas = -70 # -73\n",
    "            sec.ena = 50\n",
    "            sec.ek = -85 # -90\n",
    "            # print (\" after ek \" ) \n",
    "\n",
    "        # print(\" naf \")\n",
    "        self.distribute_channels(\"soma\", \"gbar_naf\",   0, 1, 0, 0, 0, float(par['gbar_naf_somatic']['Value']))\n",
    "        # print (\" after naf \")\n",
    "        self.distribute_channels(\"soma\", \"gbar_kaf\",   0, 1, 0, 0, 0, float(par['gbar_kaf_somatic']['Value']))\n",
    "        self.distribute_channels(\"soma\", \"gbar_kas\",   0, 1, 0, 0, 0, float(par['gbar_kas_somatic']['Value']))\n",
    "        self.distribute_channels(\"soma\", \"gbar_kdr\",   0, 1, 0, 0, 0, float(par['gbar_kdr_somatic']['Value']))\n",
    "        self.distribute_channels(\"soma\", \"gbar_bk\",    0, 1, 0, 0, 0, float(par['gbar_bk_somatic' ]['Value']))\n",
    "        self.distribute_channels(\"soma\", \"pbar_cal12\", 0, 1, 0, 0, 0, 1.34e-5)\n",
    "        self.distribute_channels(\"soma\", \"pbar_cal13\", 0, 1, 0, 0, 0, 1.34e-6)\n",
    "        self.distribute_channels(\"soma\", \"pbar_car\",   0, 1, 0, 0, 0, 1.34e-4)\n",
    "        self.distribute_channels(\"soma\", \"pbar_can\",   0, 1, 0, 0, 0,    4e-5)\n",
    "        \n",
    "        self.distribute_channels(\"dend\", \"gbar_kdr\",   0, 1, 0, 0, 0, float(par['gbar_kdr_basal']['Value']))\n",
    "        self.distribute_channels(\"dend\", \"gbar_bk\",    0, 1, 0, 0, 0, float(par['gbar_bk_basal' ]['Value']))\n",
    "\n",
    "        self.distribute_channels(\"dend\", \"pbar_cal12\", 0, 1, 0, 0, 0, 1e-5)\n",
    "        self.distribute_channels(\"dend\", \"pbar_cal13\", 0, 1, 0, 0, 0, 1e-6)\n",
    "        self.distribute_channels(\"dend\", \"pbar_car\",   0, 1, 0, 0, 0, 1e-4)\n",
    "        \n",
    "        self.distribute_channels(\"axon\", \"gbar_kas\",   0, 1, 0, 0, 0,      float(par['gbar_kas_axonal']['Value']))\n",
    "        self.distribute_channels(\"axon\", \"gbar_naf\",   3, 1, 1.1, 30, 500, float(par['gbar_naf_axonal']['Value']))\n",
    "        #self.distribute_channels(\"axon\", \"gbar_naf\",   1, 1, 0.1, 30, -1, float(par['gbar_naf_axonal']['Value']))\n",
    "        self.distribute_channels(\"axon\", \"gImbar_Im\",   0, 1, 0, 0, 0, 1.0e-3)\n",
    "\n",
    "                \n",
    "        if self.variables:\n",
    "            # print (\"variables naf \", variables['naf'], \"par['gbar_naf_basal']\" , par['gbar_naf_basal'])\n",
    "            self.distribute_channels(\"dend\", \"gbar_naf\", 1,   1.0-self.variables['naf'][1],  \\\n",
    "                                                              self.variables['naf'][1],      \\\n",
    "                                                              self.variables['naf'][2],      \\\n",
    "                                                              self.variables['naf'][3],      \\\n",
    "                                                              np.power(10,self.variables['naf'][0])*float(par['gbar_naf_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_kaf\", 1,   1.0,                      \\\n",
    "                                                              self.variables['kaf'][1],      \\\n",
    "                                                              self.variables['kaf'][2],      \\\n",
    "                                                              self.variables['kaf'][3],      \\\n",
    "                                                              np.power(10,self.variables['kaf'][0])*float(par['gbar_kaf_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_kas\", 1,   0.1,                      \\\n",
    "                                                              0.9,                      \\\n",
    "                                                              self.variables['kas'][1],      \\\n",
    "                                                              self.variables['kas'][2],      \\\n",
    "                                                              np.power(10,self.variables['kas'][0])*float(par['gbar_kas_basal']['Value']))\n",
    "                                                              \n",
    "            self.distribute_channels(\"dend\", \"gbar_kir\", 0,   np.power(10,self.variables['kir'][0]), 0, 0, 0,    float(par['gbar_kir_basal'  ]['Value']))\n",
    "            self.distribute_channels(\"soma\", \"gbar_kir\", 0,   np.power(10,self.variables['kir'][0]), 0, 0, 0,    float(par['gbar_kir_somatic']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_sk\",  0,   np.power(10,self.variables['sk' ][0]), 0, 0, 0,    float(par['gbar_sk_basal'   ]['Value']))\n",
    "            self.distribute_channels(\"soma\", \"gbar_sk\",  0,   np.power(10,self.variables['sk' ][0]), 0, 0, 0,    float(par['gbar_sk_somatic' ]['Value']))\n",
    "\n",
    "            self.distribute_channels(\"dend\", \"pbar_can\",   1, 1.0-self.variables['can'][1],  \\\n",
    "                                                              self.variables['can'][1],      \\\n",
    "                                                              self.variables['can'][2],      \\\n",
    "                                                              self.variables['can'][3],      \\\n",
    "                                                              np.power(10,self.variables['can'][0]))\n",
    "            self.distribute_channels(\"dend\", \"pbar_cav32\", 1, 0,                        \\\n",
    "                                                              1,                        \\\n",
    "                                                              self.variables['c32'][1],      \\\n",
    "                                                              self.variables['c32'][2],      \\\n",
    "                                                              np.power(10,self.variables['c32'][0]))\n",
    "            self.distribute_channels(\"dend\", \"pbar_cav33\", 1, 0,                        \\\n",
    "                                                              1,                        \\\n",
    "                                                              self.variables['c33'][1],      \\\n",
    "                                                              self.variables['c33'][2],      \\\n",
    "                                                              np.power(10,self.variables['c33'][0]))\n",
    "        else:\n",
    "            self.distribute_channels(\"dend\", \"gbar_naf\", 1, 0.1, 0.9,   60.0,   10.0, float(par['gbar_naf_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_kaf\", 1,   1, 0.5,  120.0,  -30.0, float(par['gbar_kaf_basal']['Value']))\n",
    "            #self.distribute_channels(\"dend\", \"gbar_kaf\", 0, 1, 0, 0, 0, float(par['gbar_kaf_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_kas\", 2,   1, 9.0,  0.0, -5.0, float(par['gbar_kas_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_kir\", 0, 1, 0, 0, 0, float(par['gbar_kir_basal']['Value']))\n",
    "            self.distribute_channels(\"soma\", \"gbar_kir\", 0, 1, 0, 0, 0, float(par['gbar_kir_somatic']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"gbar_sk\",  0, 1, 0, 0, 0, float(par['gbar_sk_basal']['Value']))\n",
    "            self.distribute_channels(\"soma\", \"gbar_sk\",  0, 1, 0, 0, 0, float(par['gbar_sk_basal']['Value']))\n",
    "            self.distribute_channels(\"dend\", \"pbar_can\", 0, 1, 0, 0, 0, 1e-7)\n",
    "            self.distribute_channels(\"dend\", \"pbar_cav32\", 1, 0, 1.0, 120.0, -30.0, 1e-7)\n",
    "            self.distribute_channels(\"dend\", \"pbar_cav33\", 1, 0, 1.0, 120.0, -30.0, 1e-8)\n",
    "\n",
    "    def create_sectionlists(self):\n",
    "        self.all = []\n",
    "        self.somalist = [] \n",
    "        self.nsomasec = 0                \n",
    "        self.axonlist = [] \n",
    "        self.dendlist = [] \n",
    "        # print ( \" ---- in create section list ------ \")\n",
    "        for sec in h.allsec():\n",
    "            # print ( \" sec :::: \", sec.name() ) \n",
    "            self.all.append(sec) # needs to be a keyword argument when used with h.SectionList()\n",
    "            if sec.name().find('soma') >= 0:\n",
    "                self.neuron_id_list.append(self.neuron_id)\n",
    "                print ( \" ---- @@@@@@@ found soma !!!!!!!! ------ \")\n",
    "                self.data_list.append([self.neuron_id,self.neuron_name,self.archive,self.note])\n",
    "                self.somalist.append(sec)\n",
    "                self.nsomasec += 1\n",
    "            if sec.name().find('axon') >= 0:\n",
    "                self.axonlist.append(sec)\n",
    "            if sec.name().find('dend') >= 0:\n",
    "                self.dendlist.append(sec)\n",
    "        \n",
    "    def distribute_channels(self, as1, as2, d3, a4, a5, a6, a7, g8):\n",
    "        if isinstance(self.somalist[0], list):\n",
    "            h.distance(sec=self.somalist[0][0])\n",
    "        else:\n",
    "            h.distance(sec=self.somalist[0])\n",
    "        \n",
    "        for sec in self.all:\n",
    "            if sec.name().find(as1) >= 0:\n",
    "                for seg in sec:\n",
    "                    dist = h.distance(seg.x, sec=sec)\n",
    "                    # print (\"111 d3 \", d3, \" a4 \", a4 , \" a5 \", a5, \" a6 \", a6, \" a7 \", a7, \" g8\", g8 )\n",
    "                    val = self.calculate_distribution(d3, dist, a4, a5, a6, a7, g8)\n",
    "                    cmd = 'seg.%s = %g' % (as2, val)\n",
    "                    exec(cmd)\n",
    "\n",
    "    def calculate_distribution(self, d3, dist, a4, a5, a6, a7, g8):\n",
    "        # d3 is the distribution type:\n",
    "        #     0 linear, 1 sigmoid, 2 exponential\n",
    "        #     3 step for absolute distance (in microns)\n",
    "        # dist is the somatic distance\n",
    "        # a4-a7 are distribution parameters \n",
    "        # g8 is the maximal conductance\n",
    "        if   d3 == 0: \n",
    "            value = a4 + a5*dist\n",
    "        elif d3 == 1: \n",
    "            # print (\" dist \", dist)\n",
    "            # print (\" a6 \", a6)\n",
    "\n",
    "            # print (\" dist-a6 \", dist-a6)\n",
    "            # print (\" a7 \", a7)\n",
    "            # print (\" a5 \", a5)\n",
    "            # print (\" a4 \", a4)\n",
    "            value = 0\n",
    "            try:\n",
    "                value = a4 + a5/(1 + exp((dist-a6)/a7) )\n",
    "            except:\n",
    "                traceback.print_exc(file=sys.stdout)\n",
    "                # pass\n",
    "        elif d3 == 2: \n",
    "            value = a4 + a5*exp((dist-a6)/a7)\n",
    "        elif d3 == 3:\n",
    "            if (dist > a6) and (dist < a7):\n",
    "                value = a4\n",
    "            else:\n",
    "                value = a5\n",
    "                \n",
    "        if value < 0:\n",
    "            value = 0\n",
    "            \n",
    "        value = value*g8\n",
    "        return value\n",
    "\n",
    "    def get_dendrites(self, distance_to_soma = 80):\n",
    "        distal_ind = []; proximal_ind = []; middle_ind = [];\n",
    "        \n",
    "        for ind, dend in enumerate(self.dendlist):\n",
    "            if h.distance(0, sec = dend) >= distance_to_soma:\n",
    "                distal_ind.append(ind)\n",
    "            elif h.distance(1, sec = dend) <= distance_to_soma:\n",
    "                proximal_ind.append(ind)\n",
    "            else:\n",
    "                middle_ind.append(ind)\n",
    "                \n",
    "        return distal_ind, proximal_ind, middle_ind\n",
    "\n",
    "    \n",
    "    def insert_spines(self, section_list, start_pos, end_pos, num_spines = 20):\n",
    "        spine_step = 1.0/num_spines\n",
    "        for sec in section_list:\n",
    "            for i in range(0, num_spines):\n",
    "                pos = end_pos - (end_pos - start_pos)*i*spine_step\n",
    "                spine_name = 'spine_' + self.dendlist[sec].name() + '(' + str(pos) + ')'\n",
    "                s = sp.Spine(self.dendlist[sec], spine_name)\n",
    "                self.spines.append(s)            \n",
    "                self.spines[-1].attach(self.dendlist[sec], pos, 0)\n",
    "\n",
    "    def delete_spines(self):\n",
    "        while self.spines != []:\n",
    "            for s in self.spines:\n",
    "                s.head = None                \n",
    "                s.neck = None\n",
    "                self.spines.remove(s)\n",
    "        self.num_spines_on_dends = np.zeros(len(self.dendlist))\n",
    " \n",
    "    def connect2target(self, target, thresh=10):\n",
    "        \"\"\"Make a new NetCon with this cell's membrane\n",
    "        potential at the soma as the source (i.e. the spike detector)\n",
    "        onto the target passed in (i.e. a synapse on a cell).\n",
    "        Subclasses may override with other spike detectors.\"\"\"\n",
    "        nc = h.NetCon(self.soma(1)._ref_v, target, sec = self.soma)\n",
    "        nc.threshold = thresh\n",
    "        return nc\n",
    "            \n",
    "    def insert_synapse(self, syntype, sec, pos, add_spine = 0, on_spine = 0):\n",
    "        if add_spine and on_spine:\n",
    "            print(\"Arguments add_spine and on_spine can't simultaneously be 1\")\n",
    "            sys.exit(-1)\n",
    "\n",
    "        if add_spine:\n",
    "            s_ind = [int(si) for si in re.findall(\"\\d+\", sec.name())]\n",
    "            s_ind = s_ind[0]\n",
    "            self.num_spines_on_dends[s_ind] += 1\n",
    "\n",
    "            spine_name = 'spine_' + sec.name() + '(' + str(pos) + ')'\n",
    "            self.spines.append(sp.Spine(sec, spine_name))\n",
    "            self.spines[-1].attach(sec, pos, 0)\n",
    "            self.spines[-1].syn_on = 1\n",
    "            sec = self.spines[-1].head\n",
    "            s.spinepos = pos\n",
    "            pos = 0.5\n",
    "        \n",
    "        if on_spine:\n",
    "            empty_spines = [spine for spine in self.spines if (spine.parent == sec and spine.syn_on == 0)]\n",
    "            \n",
    "            if empty_spines == []:\n",
    "                print(\"There are no empty spines on dendrite %s\" % sec.name())\n",
    "                # sys.exit(-1)\n",
    "                return\n",
    "            else:\n",
    "                sec = empty_spines[0].head\n",
    "                s.spinepos = pos\n",
    "                pos = 0.5\n",
    "                empty_spines[0].syn_on = 1\n",
    "        \n",
    "        syn = s.Synapse()\n",
    "        syn.type = syntype\n",
    "        syn.sec = sec\n",
    "        syn.pos = pos        \n",
    "        \n",
    "        if syntype in ['expsyn', 'expsyn_plateau']:\n",
    "            syn.obj = h.ExpSyn(sec(pos))            \n",
    "            syn.obj.tau = p.esyn_tau\n",
    "            syn.obj.e = p.e_esyn\n",
    "            self.esyn.append(syn)\n",
    "            return syn\n",
    "        \n",
    "        elif syntype == 'inhexpsyn' or syntype == 'inhexpsyn_plateau':\n",
    "            syn.obj = h.InhExpSyn(sec(pos))\n",
    "            if syntype == 'inhexpsyn':       \n",
    "                syn.obj.tau = p.isyn_tau\n",
    "            elif syntype == 'inhexpsyn_plateau':\n",
    "                syn.obj.tau = p.isyn_plateau_tau\n",
    "            syn.obj.e = p.e_gaba\n",
    "            self.isyn.append(syn)\n",
    "            return self.isyn[-1]\n",
    "            \n",
    "        elif syntype == 'exp2syn':\n",
    "            syn.obj = h.Exp2Syn(sec(pos))\n",
    "            syn.obj.e = p.e_esyn\n",
    "            syn.obj.tau2 = p.tau2_exp2syn\n",
    "            syn.obj.tau1 = p.tau1_exp2syn\n",
    "            self.esyn.append(syn)\n",
    "            return syn\n",
    "\n",
    "        elif syntype == 'inhexp2syn':\n",
    "            syn.obj = h.InhExp2Syn(sec(pos))\n",
    "            syn.obj.e = p.e_gaba\n",
    "            syn.obj.tau2 = p.tau2_inhexp2syn\n",
    "            syn.obj.tau1 = p.tau1_inhexp2syn\n",
    "            self.isyn.append(syn)\n",
    "            return syn\n",
    "            \n",
    "        elif syntype == 'tmGlut':\n",
    "            syn.obj = h.tmGlut(sec(pos))\n",
    "            syn.obj.tau1_nmda = p.tau1_NMDA\n",
    "            syn.obj.tau2_nmda = p.tau2_NMDA\n",
    "            syn.obj.nmda_ratio = p.ratio_glutamate_syn\n",
    "            syn.obj.U = 0.9\n",
    "            syn.obj.tauF = 5.0\n",
    "            self.esyn.append(syn)\n",
    "            return syn\n",
    "\n",
    "        elif syntype == 'glutamate' or syntype == 'glutamate_plateau':\n",
    "            syn.obj = h.glutamate(sec(pos))\n",
    "            syn.obj.mg = p.Mg\n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.tau1_nmda = p.tau1_NMDA\n",
    "            syn.obj.tau2_nmda = p.tau2_NMDA\n",
    "            syn.obj.ratio = p.ratio_glutamate_syn\n",
    "            self.esyn.append(syn)\n",
    "            return syn\n",
    "\n",
    "        elif syntype in ['glutamate_ica_nmda', 'glutamate_xor_test'] :\n",
    "            syn.obj = h.glutamate_ica_nmda(sec(pos))\n",
    "            syn.obj.mg = p.Mg            \n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.tau1_nmda = p.tau1_NMDA\n",
    "            syn.obj.tau2_nmda = p.tau2_NMDA\n",
    "            \n",
    "            syn.obj.w_ampa = p.gAMPAmax_plateau \n",
    "            syn.obj.w_nmda = p.gNMDAmax_plateau\n",
    "            \n",
    "            syn.obj.nmda_ca_fraction = p.nmda_ca_fraction\n",
    "            self.esyn.append(syn)\n",
    "            return syn\n",
    "\n",
    "        elif syntype in ['AMPA' ,'AMPA_test', 'AMPA_pf', 'AMPA_stp']:\n",
    "            if syntype in ['AMPA', 'AMPA_pf']:\n",
    "                syn.obj = h.AMPA(sec(pos))\n",
    "            elif syntype in ['AMPA_stp']:\n",
    "                syn.obj = h.AMPA_stp(sec(pos))\n",
    "                syn.obj.U = p.U\n",
    "                syn.obj.u0 = p.u0\n",
    "            elif syntype == 'AMPA_test':\n",
    "                syn.obj = h.AMPA_test(sec(pos))\n",
    "                syn.obj.weight = p.weight\n",
    "            syn.obj.gmax = p.gmaxAMPA_spillover\n",
    "            if syntype == 'AMPA_pf':\n",
    "                syn.obj.gmax = p.gmaxAMPA_pf\n",
    "            self.esyn.append(syn)\n",
    "            return syn         \n",
    "        \n",
    "        elif syntype in [ 'NMDA', 'NMDA_test', 'NMDAe', 'NMDA_pf', 'NMDA_stp']:\n",
    "            if syntype in ['NMDA', 'NMDA_pf']:\n",
    "                syn.obj = h.NMDA(sec(pos))\n",
    "            elif syntype in ['NMDA_stp']:\n",
    "                syn.obj = h.NMDA_stp(sec(pos))\n",
    "                syn.obj.U = p.U\n",
    "                syn.obj.u0 = p.u0\n",
    "            elif syntype == 'NMDA_test':\n",
    "                syn.obj = h.NMDA_test(sec(pos))\n",
    "            elif syntype ==  'NMDAe':\n",
    "                syn.obj = h.NMDAe(sec(pos))\n",
    "            syn.obj.mg = p.Mg\n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.Cdur = p.Cdur\n",
    "            if syntype in ['NMDA', 'NMDA_test', 'NMDA_stp']:    \n",
    "                syn.obj.gmax = p.gmaxNMDA_spillover\n",
    "            elif syntype in ['NMDA_pf']:    \n",
    "                syn.obj.gmax = p.gmaxNMDA_pf\n",
    "            elif syntype in ['NMDAe']:\n",
    "                syn.obj.gmax = p.gmaxNMDAe_spillover\n",
    "                syn.obj.Cdur_init = p.eCdur_init\n",
    "                syn.obj.Cdur_factor = p.eCdur_factor\n",
    "                syn.obj.weight = p.exglu_weight\n",
    "            syn.obj.Beta = p.Beta\n",
    "            syn.obj.nmda_ca_fraction = p.nmda_ca_fraction\n",
    "            if syntype == 'NMDA_test':\n",
    "                syn.obj.weight = p.weight\n",
    "            \n",
    "            self.esyn.append(syn)\n",
    "            return syn        \n",
    "\n",
    "        elif syntype in ['adaptive_shom_AMPA', 'adaptive_shom_AMPA_stp']:\n",
    "            if syntype in ['adaptive_shom_AMPA']:\n",
    "                syn.obj = h.adaptive_shom_AMPA(sec(pos))\n",
    "            else:\n",
    "                syn.obj = h.adaptive_shom_AMPA_stp(sec(pos))\n",
    "                syn.obj.U = p.U\n",
    "                syn.obj.u0 = p.u0\n",
    "                \n",
    "            syn.obj.gmax = p.gmaxAMPA_spillover\n",
    "            \n",
    "            self.esyn.append(syn)\n",
    "            return syn        \n",
    "\n",
    "        elif syntype == 'adaptive_pf_AMPA':\n",
    "            syn.obj = h.adaptive_pf_AMPA(sec(pos))\n",
    "            syn.obj.gmax = p.gmaxAMPA_pf\n",
    "            \n",
    "            self.esyn.append(syn)\n",
    "            return syn               \n",
    "        \n",
    "        elif syntype in ['adaptive_shom_NMDA','adaptive_shom_NMDA_stp','adaptive_my_shom_NMDA']:\n",
    "            if syntype in ['adaptive_shom_NMDA']:\n",
    "                syn.obj = h.adaptive_shom_NMDA(sec(pos))\n",
    "            elif syntype in ['adaptive_shom_NMDA_stp']:\n",
    "                syn.obj = h.adaptive_shom_NMDA_stp(sec(pos))\n",
    "                syn.obj.U = p.U\n",
    "                syn.obj.u0 = p.u0\n",
    "            else:\n",
    "                syn.obj = h.adaptive_my_shom_NMDA(sec(pos))\n",
    "            \n",
    "            syn.obj.mg = p.Mg\n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.gmax = p.gmaxNMDA_spillover\n",
    "            syn.obj.Beta = p.Beta\n",
    "            syn.obj.Cdur = p.Cdur\n",
    "            syn.obj.nmda_ca_fraction = p.nmda_ca_fraction\n",
    "            \n",
    "            syn.obj.w0 = p.weight            \n",
    "            syn.obj.learning_rate_w_LTP = p.learning_rate_w_LTP\n",
    "            syn.obj.learning_rate_w_LTD = p.learning_rate_w_LTD\n",
    "            syn.obj.learning_rate_thresh_LTP = p.learning_rate_thresh_LTP\n",
    "            syn.obj.learning_rate_thresh_LTD = p.learning_rate_thresh_LTD\n",
    "            syn.obj.learning_rate_thresh_KD_LTD = p.learning_rate_thresh_KD_LTD\n",
    "            syn.obj.KD1 = p.KD1\n",
    "            syn.obj.n1 = p.n1\n",
    "            syn.obj.KD2 = p.KD2\n",
    "            syn.obj.n2 = p.n2\n",
    "            syn.obj.KD_LTD = p.KD_LTD\n",
    "            syn.obj.n_LTD = p.n_LTD    \n",
    "\n",
    "            self.esyn.append(syn)\n",
    "            return syn  \n",
    "\n",
    "        elif syntype == 'adaptive_pf_NMDA':\n",
    "            syn.obj = h.adaptive_pf_NMDA(sec(pos))\n",
    "            \n",
    "            syn.obj.mg = p.Mg\n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.gmax = p.gmaxNMDA_pf\n",
    "            syn.obj.Beta = p.Beta\n",
    "            syn.obj.Cdur = p.Cdur_pf\n",
    "            syn.obj.nmda_ca_fraction = p.nmda_ca_fraction\n",
    "            \n",
    "            syn.obj.w0 = p.weight            \n",
    "            syn.obj.learning_rate_w_LTP = p.learning_rate_w_LTP\n",
    "            syn.obj.learning_rate_w_LTD = p.learning_rate_w_LTD_pf\n",
    "            syn.obj.learning_rate_thresh_LTP = p.learning_rate_thresh_LTP\n",
    "            syn.obj.learning_rate_thresh_LTD = p.learning_rate_thresh_LTD\n",
    "            syn.obj.KD_LTD = p.KD_LTD_pf\n",
    "            syn.obj.n_LTD = p.n_LTD_pf\n",
    "            \n",
    "            self.esyn.append(syn)\n",
    "            return syn  \n",
    "\n",
    "        elif syntype == 'adaptive_NMDAe':\n",
    "            syn.obj = h.adaptive_NMDAe(sec(pos))\n",
    "            syn.obj.mg = p.Mg\n",
    "            syn.obj.eta = p.eta\n",
    "            syn.obj.alpha = p.alpha\n",
    "            syn.obj.Erev = p.erev_NMDA\n",
    "            syn.obj.gmax = p.gmaxNMDAe_spillover\n",
    "            syn.obj.Beta = p.Beta\n",
    "            syn.obj.Cdur = p.eCdur\n",
    "            syn.obj.Cdur_init = p.eCdur_init\n",
    "            syn.obj.Cdur_factor = p.eCdur_factor\n",
    "            syn.obj.nmda_ca_fraction = p.nmda_ca_fraction\n",
    "            \n",
    "            self.esyn.append(syn)\n",
    "            return syn           \n",
    "        \n",
    "        else: \n",
    "            print(\"From method cell.insert_synapse\")\n",
    "            print(\"Syntype '%s' not supported\" % syntype)\n",
    "            sys.exit(-1)\n",
    "\n",
    "    def max_dist(self, axon_excluding=True):\n",
    "        if not hasattr(self, 'somalist'):\n",
    "            raise NotImplementedError(\"create_sectionlists() is not implemented or attribute somalist not defined\")\n",
    "        \n",
    "        # h.distance(sec=self.somalist[0])\n",
    "        if isinstance(self.somalist[0], list):\n",
    "            print ( \" soma is list \" ) \n",
    "            h.distance(sec=self.somalist[0][0])\n",
    "        else:\n",
    "            print ( \" soma is not ****** list \" ) \n",
    "            h.distance(sec=self.somalist[0])\n",
    "        dmax = 0\n",
    "        for sec in self.all:\n",
    "            if axon_excluding and sec.name().find('axon') == 0: \n",
    "                continue\n",
    "                \n",
    "            dmax = max(dmax, h.distance(1, sec=sec))\n",
    "            print ( \" dmax is ----- \" , dmax)\n",
    "        return dmax, sec\n",
    "        \n",
    "    def get_nsegs(self):\n",
    "        \"\"\"Returns the number of segments in the neuron model.\"\"\"\n",
    "        nsegs = 0\n",
    "        for sec in self.all: \n",
    "            nsegs += sec.nseg\n",
    "        return nsegs\n",
    "        \n",
    "    def set_nsegs(self):\n",
    "        \"\"\"Sets the number of segments in each section of the neuron model\n",
    "        according to n = 2*int(L/40) + 1, where L is the length of the section.\"\"\"\n",
    "        for sec in self.all:\n",
    "            sec.nseg = 2*int(sec.L/40.0)+1\n",
    "        if hasattr(self, 'axonlist'):\n",
    "            for sec in self.axonlist:\n",
    "                sec.nseg = 2  # two segments in axon initial segment\n",
    "\n",
    "    def total_dend_length(self):\n",
    "        \"\"\"Returns the total dendritic length.\"\"\"\n",
    "        total_length = 0             \n",
    "        for dend in self.dendlist:\n",
    "            total_length += dend.L\n",
    "        return total_length\n",
    "        \n",
    "    def increase_dend_res(self, dend_list, mult):\n",
    "        for d in dend_list:\n",
    "            self.dendlist[d].nseg *= mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5de2dd49-ecc1-402c-9ddf-d2e0b9e6e476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ********* \n",
      "Apr13IR3b\n",
      "../all_morphologies/luebke/CNG version/Apr13IR3b.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "Apr13IR2b\n",
      "../all_morphologies/luebke/CNG version/Apr13IR2b.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "Apr13IR2c\n",
      "../all_morphologies/luebke/CNG version/Apr13IR2c.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "WT-D1-Jun19IR2a-whole-cell\n",
      "../all_morphologies/luebke/CNG version/WT-D1-Jun19IR2a-whole-cell.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "80_01\n",
      "../all_morphologies/almuhtasib/CNG version/80_01.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "7_39\n",
      "../all_morphologies/almuhtasib/CNG version/7_39.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "78_02\n",
      "../all_morphologies/almuhtasib/CNG version/78_02.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "10_44\n",
      "../all_morphologies/almuhtasib/CNG version/10_44.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "23_15\n",
      "../all_morphologies/almuhtasib/CNG version/23_15.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "16_29\n",
      "../all_morphologies/almuhtasib/CNG version/16_29.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "30_8\n",
      "../all_morphologies/almuhtasib/CNG version/30_8.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "19_22\n",
      "../all_morphologies/almuhtasib/CNG version/19_22.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "33_8\n",
      "../all_morphologies/almuhtasib/CNG version/33_8.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "11_44\n",
      "../all_morphologies/almuhtasib/CNG version/11_44.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "50_2\n",
      "../all_morphologies/almuhtasib/CNG version/50_2.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "29_10\n",
      "../all_morphologies/almuhtasib/CNG version/29_10.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "79_01\n",
      "../all_morphologies/almuhtasib/CNG version/79_01.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "21_19\n",
      "../all_morphologies/almuhtasib/CNG version/21_19.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "9_39\n",
      "../all_morphologies/almuhtasib/CNG version/9_39.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "18_23\n",
      "../all_morphologies/almuhtasib/CNG version/18_23.CNG.swc\n",
      " $$ D2 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "Petroccione_et_al_2023_KO\n",
      "../all_morphologies/scimemi/CNG version/Petroccione_et_al_2023_KO.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      "Petroccione_et_al_2023_KO\n",
      "../all_morphologies/scimemi/CNG version/Petroccione_et_al_2023_KO.CNG.swc\n",
      " $$ D1 $$ \n",
      " ---- @@@@@@@ found soma !!!!!!!! ------ \n",
      " all d1 =  11\n",
      " d1 good  11\n",
      " d1 bad  0\n",
      " all d2  11\n",
      " d2 good  11\n",
      " d2 bad  0\n"
     ]
    }
   ],
   "source": [
    "sim = nmda_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9477ad39-2d21-475e-9878-492c3f4cfc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphology/WT-dMSN_P270-20_1.02_SGA1-m24.swc\n"
     ]
    }
   ],
   "source": [
    "!ls morphology/WT-dMSN_P270-20_1.02_SGA1-m24.swc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f69463-301b-400a-a6c1-c5df1c40fcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
